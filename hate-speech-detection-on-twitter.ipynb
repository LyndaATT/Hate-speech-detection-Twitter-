{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Installing needed libraries","metadata":{}},{"cell_type":"code","source":"!pip install openpyxl\n!pip install PyArabic\n!pip install git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git &> /dev/null\n!pip install emoji \n!pip install Arabic-Stopwords\n!pip install tkseem\n!pip install tnkeeh\n!pip3 install fr-word-segment\n!pip install pyspellchecker","metadata":{"_kg_hide-output":false,"scrolled":true,"execution":{"iopub.status.busy":"2022-02-20T17:52:28.866970Z","iopub.execute_input":"2022-02-20T17:52:28.867557Z","iopub.status.idle":"2022-02-20T17:54:17.503016Z","shell.execute_reply.started":"2022-02-20T17:52:28.867455Z","shell.execute_reply":"2022-02-20T17:54:17.501900Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## 2. Imports","metadata":{}},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport pandas as pd\nfrom keras.preprocessing.text import Tokenizer\n\nimport nltk\nimport string\nfrom french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\nfrom fastai.text.all import *\n\nimport sklearn\nimport regex as re\nfrom unicodedata import normalize\n\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.sequence import pad_sequences\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import AdamW\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.transforms import ToTensor\nfrom torch.autograd import Variable\nfrom torch.optim.lr_scheduler import CyclicLR\nfrom torchvision import models\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix,precision_score,recall_score,f1_score\nimport os\nimport gensim\n\n\n# keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import GRU,MaxPooling1D,GlobalMaxPooling1D,Conv1D, Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\nfrom keras import callbacks\nfrom keras.utils.vis_utils import plot_model\n\n# sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer \nfrom sklearn.metrics import roc_auc_score, accuracy_score,roc_curve, auc, plot_confusion_matrix, confusion_matrix\nfrom sklearn.svm import LinearSVC\nfrom sklearn import model_selection\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.manifold import TSNE\nfrom sklearn.naive_bayes import MultinomialNB\nfrom keras.preprocessing.text import Tokenizer\nimport emoji\nfrom keras.models import Model\nimport seaborn as sn\nimport pyarabic.araby as ar\nimport tkseem as tk\nimport tnkeeh as tn\nfrom nltk.stem.isri import ISRIStemmer\nfrom spellchecker import SpellChecker\nfrom wordsegment import load,segment\nfrom keras.layers.merge import Concatenate\nimport tensorflow as tf\nload()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:54:17.504931Z","iopub.execute_input":"2022-02-20T17:54:17.505161Z","iopub.status.idle":"2022-02-20T17:54:30.080103Z","shell.execute_reply.started":"2022-02-20T17:54:17.505133Z","shell.execute_reply":"2022-02-20T17:54:30.079031Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 3. Loading Data","metadata":{}},{"cell_type":"code","source":"df_ar = pd.read_csv('/kaggle/input/twitter/ar_dataset.csv')\ndf_ar2 = pd.read_excel('/kaggle/input/twitter/arr.xlsx')\n\n#main data\ndf_fr = pd.read_csv('/kaggle/input/twitter/fr_dataset.csv')\ndf_fr2 = pd.read_csv('/kaggle/input/twitter/french_tweets.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:13.975375Z","iopub.execute_input":"2022-02-20T18:40:13.976223Z","iopub.status.idle":"2022-02-20T18:40:17.377669Z","shell.execute_reply.started":"2022-02-20T18:40:13.976179Z","shell.execute_reply":"2022-02-20T18:40:17.376772Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"markdown","source":"## 4. Exploring data","metadata":{}},{"cell_type":"markdown","source":"### 4.1 French Dataset","metadata":{}},{"cell_type":"markdown","source":"#### 4.1.1 Main dataset","metadata":{}},{"cell_type":"code","source":"df_fr.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:17.379274Z","iopub.execute_input":"2022-02-20T18:40:17.379551Z","iopub.status.idle":"2022-02-20T18:40:17.392627Z","shell.execute_reply.started":"2022-02-20T18:40:17.379521Z","shell.execute_reply":"2022-02-20T18:40:17.391779Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"df_fr.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:17.394003Z","iopub.execute_input":"2022-02-20T18:40:17.394520Z","iopub.status.idle":"2022-02-20T18:40:17.407970Z","shell.execute_reply.started":"2022-02-20T18:40:17.394484Z","shell.execute_reply":"2022-02-20T18:40:17.407384Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"print('Size of the dataset:')\nlen(df_fr)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:17.409651Z","iopub.execute_input":"2022-02-20T18:40:17.410069Z","iopub.status.idle":"2022-02-20T18:40:17.415972Z","shell.execute_reply.started":"2022-02-20T18:40:17.410038Z","shell.execute_reply":"2022-02-20T18:40:17.415170Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"#test if the data contains null values\nprint('Nan value',df_fr.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:17.417621Z","iopub.execute_input":"2022-02-20T18:40:17.418155Z","iopub.status.idle":"2022-02-20T18:40:17.430267Z","shell.execute_reply.started":"2022-02-20T18:40:17.418107Z","shell.execute_reply":"2022-02-20T18:40:17.429731Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"#take a look at the column of the dataframe to see the features\ndf_fr.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:17.719663Z","iopub.execute_input":"2022-02-20T18:40:17.719961Z","iopub.status.idle":"2022-02-20T18:40:17.725639Z","shell.execute_reply.started":"2022-02-20T18:40:17.719932Z","shell.execute_reply":"2022-02-20T18:40:17.724963Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"#### Class distribution \ncum = df_fr['target'].value_counts().to_frame()\ncum['HITId'] = cum.index\ncumfig, ax = plt.subplots(figsize=(5,5))\nsn.barplot(data=cum,x='HITId',y='target',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:18.177626Z","iopub.execute_input":"2022-02-20T18:40:18.177938Z","iopub.status.idle":"2022-02-20T18:40:18.398100Z","shell.execute_reply.started":"2022-02-20T18:40:18.177902Z","shell.execute_reply":"2022-02-20T18:40:18.397236Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"markdown","source":"#### 4.1.2 Assest dataset","metadata":{}},{"cell_type":"code","source":"df_fr2.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:19.549979Z","iopub.execute_input":"2022-02-20T18:40:19.550477Z","iopub.status.idle":"2022-02-20T18:40:19.560675Z","shell.execute_reply.started":"2022-02-20T18:40:19.550427Z","shell.execute_reply":"2022-02-20T18:40:19.560027Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"code","source":"print('Size of the dataset:')\nlen(df_fr2)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:20.274016Z","iopub.execute_input":"2022-02-20T18:40:20.274535Z","iopub.status.idle":"2022-02-20T18:40:20.280315Z","shell.execute_reply.started":"2022-02-20T18:40:20.274492Z","shell.execute_reply":"2022-02-20T18:40:20.279602Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"#test if the data contains null values\nprint('Nan value',df_fr2.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:21.053867Z","iopub.execute_input":"2022-02-20T18:40:21.054288Z","iopub.status.idle":"2022-02-20T18:40:21.245486Z","shell.execute_reply.started":"2022-02-20T18:40:21.054256Z","shell.execute_reply":"2022-02-20T18:40:21.244866Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"markdown","source":"### 4.2 Arabic dataset","metadata":{}},{"cell_type":"markdown","source":"#### 4.2.1 Main dataset","metadata":{}},{"cell_type":"code","source":"df_ar.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:23.147309Z","iopub.execute_input":"2022-02-20T18:40:23.147757Z","iopub.status.idle":"2022-02-20T18:40:23.161101Z","shell.execute_reply.started":"2022-02-20T18:40:23.147725Z","shell.execute_reply":"2022-02-20T18:40:23.160274Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"df_ar.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:23.766602Z","iopub.execute_input":"2022-02-20T18:40:23.767040Z","iopub.status.idle":"2022-02-20T18:40:23.783304Z","shell.execute_reply.started":"2022-02-20T18:40:23.767007Z","shell.execute_reply":"2022-02-20T18:40:23.782419Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"print('Size of the dataset:')\nlen(df_ar)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:24.429208Z","iopub.execute_input":"2022-02-20T18:40:24.429893Z","iopub.status.idle":"2022-02-20T18:40:24.436149Z","shell.execute_reply.started":"2022-02-20T18:40:24.429858Z","shell.execute_reply":"2022-02-20T18:40:24.435491Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"#test if the data contains null values\nprint('Nan value',df_ar.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:25.116181Z","iopub.execute_input":"2022-02-20T18:40:25.117003Z","iopub.status.idle":"2022-02-20T18:40:25.126416Z","shell.execute_reply.started":"2022-02-20T18:40:25.116964Z","shell.execute_reply":"2022-02-20T18:40:25.125573Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"#### Class distribution \ncum = df_ar['target'].value_counts().to_frame()\ncum['HITId'] = cum.index\ncumfig, ax = plt.subplots(figsize=(5,5))\nsn.barplot(data=cum,x='HITId',y='target',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:25.894353Z","iopub.execute_input":"2022-02-20T18:40:25.894899Z","iopub.status.idle":"2022-02-20T18:40:26.117754Z","shell.execute_reply.started":"2022-02-20T18:40:25.894861Z","shell.execute_reply":"2022-02-20T18:40:26.117096Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2.2 Assest dataset","metadata":{}},{"cell_type":"code","source":"df_ar2.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:27.805133Z","iopub.execute_input":"2022-02-20T18:40:27.805835Z","iopub.status.idle":"2022-02-20T18:40:27.818084Z","shell.execute_reply.started":"2022-02-20T18:40:27.805785Z","shell.execute_reply":"2022-02-20T18:40:27.817192Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"print('Size of the dataset:')\nlen(df_ar2)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:28.826868Z","iopub.execute_input":"2022-02-20T18:40:28.827192Z","iopub.status.idle":"2022-02-20T18:40:28.834638Z","shell.execute_reply.started":"2022-02-20T18:40:28.827141Z","shell.execute_reply":"2022-02-20T18:40:28.833623Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"#test if the data contains null values\nprint('Nan value',df_ar2.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:29.888455Z","iopub.execute_input":"2022-02-20T18:40:29.889126Z","iopub.status.idle":"2022-02-20T18:40:29.898664Z","shell.execute_reply.started":"2022-02-20T18:40:29.889088Z","shell.execute_reply":"2022-02-20T18:40:29.897575Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"markdown","source":"## 5. Preprocessing on the datasets","metadata":{}},{"cell_type":"markdown","source":"### 5.1 French Dataset","metadata":{}},{"cell_type":"markdown","source":"#### 5.1.1 Hateful tweets","metadata":{}},{"cell_type":"code","source":"# negative tweets contained\n# we put target = 0 negative\nneg = df_fr.loc[df_fr['target']!='normal','target'] = 0\nneg = df_fr","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:32.449938Z","iopub.execute_input":"2022-02-20T18:40:32.450228Z","iopub.status.idle":"2022-02-20T18:40:32.457199Z","shell.execute_reply.started":"2022-02-20T18:40:32.450198Z","shell.execute_reply":"2022-02-20T18:40:32.456585Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.1 No hateful tweets","metadata":{}},{"cell_type":"code","source":"#positive tweets contained in the assest dataset\npos = df_fr2.loc[df_fr2['label']==1]\n#since we have a several amount of data, we take a part of it\npos= pos.rename(columns={'label':'target','text':'tweet'})\nn = len(pos)\npos= pos[0:int(n/100)]","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:33.870392Z","iopub.execute_input":"2022-02-20T18:40:33.871488Z","iopub.status.idle":"2022-02-20T18:40:33.941837Z","shell.execute_reply.started":"2022-02-20T18:40:33.871440Z","shell.execute_reply":"2022-02-20T18:40:33.940875Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.3 Merging ","metadata":{}},{"cell_type":"code","source":"# merging the two dataframes\ndata_fr = pd.concat([neg,pos], ignore_index=True, sort=False)\ndata_fr.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:35.282691Z","iopub.execute_input":"2022-02-20T18:40:35.283288Z","iopub.status.idle":"2022-02-20T18:40:35.304736Z","shell.execute_reply.started":"2022-02-20T18:40:35.283248Z","shell.execute_reply":"2022-02-20T18:40:35.303828Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"code","source":"# fixing nan values\ndata_fr.loc[data_fr['sentiment'].isnull().values==True,'sentiment'] = 'normal'\ndata_fr.loc[data_fr['directness'].isnull().values==True,'directness'] = 'direct'\ndata_fr.loc[data_fr['group'].isnull().values==True,'group'] = 'nothing'\ndata_fr.loc[data_fr['annotator_sentiment'].isnull().values==True,'annotator_sentiment'] = 'indifference'\ndata_fr = data_fr.sample(frac = 1)\ndata_fr.reindex().head()\ndata_fr = data_fr.drop(columns={'HITId'})\ndata_fr.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:36.026279Z","iopub.execute_input":"2022-02-20T18:40:36.026971Z","iopub.status.idle":"2022-02-20T18:40:36.059369Z","shell.execute_reply.started":"2022-02-20T18:40:36.026914Z","shell.execute_reply":"2022-02-20T18:40:36.058487Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.4 Distribution of data ","metadata":{}},{"cell_type":"code","source":"# distribution of classes: 0,1\ncum = data_fr['target'].value_counts().to_frame()\ncum['tweet'] = cum.index\ncumfig, ax = plt.subplots(figsize=(5,5))\nsn.barplot(data=cum,x='tweet',y='target',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:37.695061Z","iopub.execute_input":"2022-02-20T18:40:37.695987Z","iopub.status.idle":"2022-02-20T18:40:37.885317Z","shell.execute_reply.started":"2022-02-20T18:40:37.695944Z","shell.execute_reply":"2022-02-20T18:40:37.884414Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.pie(data_fr[\"target\"].value_counts(),labels=data_fr[\"target\"].value_counts().index,autopct=lambda p:f'{p:.2f}%',\n        shadow=True,colors=['mediumvioletred','darkturquoise'],labeldistance = 1.1,textprops={'fontsize': 14})\n\nplt.savefig(\"distribution des données dans les différentes classes.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:38.496733Z","iopub.execute_input":"2022-02-20T18:40:38.497670Z","iopub.status.idle":"2022-02-20T18:40:38.656669Z","shell.execute_reply.started":"2022-02-20T18:40:38.497617Z","shell.execute_reply":"2022-02-20T18:40:38.654251Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.5 Encoding columns","metadata":{}},{"cell_type":"code","source":"#encoding labels\nle = preprocessing.LabelEncoder()\ndata_fr.sentiment = le.fit_transform(data_fr.sentiment)\ndata_fr.directness = le.fit_transform(data_fr.directness)\ndata_fr.annotator_sentiment = le.fit_transform(data_fr.annotator_sentiment)\ndata_fr.group = le.fit_transform(data_fr.group)\ndata_fr = data_fr.sample(frac = 1)\ndata_fr","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:40.748706Z","iopub.execute_input":"2022-02-20T18:40:40.750288Z","iopub.status.idle":"2022-02-20T18:40:40.794775Z","shell.execute_reply.started":"2022-02-20T18:40:40.750190Z","shell.execute_reply":"2022-02-20T18:40:40.793843Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"markdown","source":"### 5.2 Arabic dataset","metadata":{}},{"cell_type":"markdown","source":"#### 5.2.1 Hateful tweets","metadata":{}},{"cell_type":"code","source":"neg = df_ar.loc[df_ar['target']!='normal','target'] = 0\nneg = df_ar\nneg.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:50.157990Z","iopub.execute_input":"2022-02-20T18:40:50.158428Z","iopub.status.idle":"2022-02-20T18:40:50.173124Z","shell.execute_reply.started":"2022-02-20T18:40:50.158394Z","shell.execute_reply":"2022-02-20T18:40:50.172042Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2.2 No Hateful tweets","metadata":{}},{"cell_type":"code","source":"#positive tweets contained in the assest dataset\ndf_ar2.loc[df_ar2['Sentiment']=='Positive']\ndf_ar2.loc[df_ar2['Sentiment']=='Positive','Sentiment'] = 1\npos = df_ar2.loc[df_ar2[\"Sentiment\"]==1]\npos= pos.rename(columns={'Sentiment':'target','Feed':'tweet'})\npos = pos.drop(columns={'ID'})","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:51.836084Z","iopub.execute_input":"2022-02-20T18:40:51.836431Z","iopub.status.idle":"2022-02-20T18:40:51.863553Z","shell.execute_reply.started":"2022-02-20T18:40:51.836393Z","shell.execute_reply":"2022-02-20T18:40:51.862743Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2.3 Merging","metadata":{}},{"cell_type":"code","source":"# merging the two dataframes\ndata_ar = pd.concat([neg[0:int(len(pos)/1.5)],pos], ignore_index=True, sort=False)\ndata_ar.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:54.039884Z","iopub.execute_input":"2022-02-20T18:40:54.040362Z","iopub.status.idle":"2022-02-20T18:40:54.057927Z","shell.execute_reply.started":"2022-02-20T18:40:54.040317Z","shell.execute_reply":"2022-02-20T18:40:54.057006Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"data_ar.loc[data_ar['sentiment'].isnull().values==True,'sentiment'] = 'normal'\ndata_ar.loc[data_ar['directness'].isnull().values==True,'directness'] = 'direct'\ndata_ar.loc[data_ar['group'].isnull().values==True,'group'] = 'nothing'\ndata_ar.loc[data_ar['annotator_sentiment'].isnull().values==True,'annotator_sentiment'] = 'indifference'\ndata_ar = data_ar.sample(frac = 1)\ndata_ar = data_ar.sample(frac = 1)\ndata_ar.drop(columns='HITId')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:54.816490Z","iopub.execute_input":"2022-02-20T18:40:54.816911Z","iopub.status.idle":"2022-02-20T18:40:54.849906Z","shell.execute_reply.started":"2022-02-20T18:40:54.816879Z","shell.execute_reply":"2022-02-20T18:40:54.848969Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2.4 Data distribution before resampling","metadata":{}},{"cell_type":"code","source":"# distribution of classes: 0,1\ncum = data_ar['target'].value_counts().to_frame()\ncum['tweet'] = cum.index\ncumfig, ax = plt.subplots(figsize=(5,5))\nsn.barplot(data=cum,x='tweet',y='target',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:40:56.607414Z","iopub.execute_input":"2022-02-20T18:40:56.607722Z","iopub.status.idle":"2022-02-20T18:40:56.790195Z","shell.execute_reply.started":"2022-02-20T18:40:56.607687Z","shell.execute_reply":"2022-02-20T18:40:56.789258Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2.5 Resampling","metadata":{}},{"cell_type":"code","source":"def resample(df):\n    setnew = df\n    lab0,lab1 = setnew[setnew['target'] == 0], setnew[setnew['target'] == 1]\n    c0, c1 = setnew['target'].value_counts()\n  \n    lab0_sampled = lab0.sample(c0, replace=True) \n    lab1_sampled = lab1.sample(3*c1, replace=True)\n\n    setnew_resampled = pd.concat([lab0_sampled,lab1_sampled], axis=0)\n    setnew_resampled = setnew_resampled.sample(frac = 1)\n    return setnew_resampled","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:06.664573Z","iopub.execute_input":"2022-02-20T18:41:06.665363Z","iopub.status.idle":"2022-02-20T18:41:06.673556Z","shell.execute_reply.started":"2022-02-20T18:41:06.665300Z","shell.execute_reply":"2022-02-20T18:41:06.672610Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"data_ar = resample(data_ar)\ndata_ar = data_ar.drop(columns={'HITId'})\ndata_ar.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:07.587961Z","iopub.execute_input":"2022-02-20T18:41:07.588304Z","iopub.status.idle":"2022-02-20T18:41:07.609674Z","shell.execute_reply.started":"2022-02-20T18:41:07.588260Z","shell.execute_reply":"2022-02-20T18:41:07.608522Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2.6 Data distribution after resampling","metadata":{}},{"cell_type":"code","source":"# distribution of classes: 0,1\ncum = data_ar['target'].value_counts().to_frame()\ncum['tweet'] = cum.index\ncumfig, ax = plt.subplots(figsize=(5,5))\nsn.barplot(data=cum,x='tweet',y='target',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:09.647520Z","iopub.execute_input":"2022-02-20T18:41:09.648324Z","iopub.status.idle":"2022-02-20T18:41:09.785442Z","shell.execute_reply.started":"2022-02-20T18:41:09.648285Z","shell.execute_reply":"2022-02-20T18:41:09.784539Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.pie(data_ar[\"target\"].value_counts(),labels=data_ar[\"target\"].value_counts().index,autopct=lambda p:f'{p:.2f}%',\n        shadow=True,colors=['mediumvioletred','darkturquoise'],labeldistance = 1.1,textprops={'fontsize': 14})\n\nplt.savefig(\" ara distribution des données dans les différentes classes.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:10.987372Z","iopub.execute_input":"2022-02-20T18:41:10.988162Z","iopub.status.idle":"2022-02-20T18:41:11.137726Z","shell.execute_reply.started":"2022-02-20T18:41:10.988120Z","shell.execute_reply":"2022-02-20T18:41:11.136560Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2.7 Encoding columns\n","metadata":{}},{"cell_type":"code","source":"data_ar.sentiment = le.fit_transform(data_ar.sentiment)\ndata_ar.directness = le.fit_transform(data_ar.directness)\ndata_ar.annotator_sentiment = le.fit_transform(data_ar.annotator_sentiment)\ndata_ar.group = le.fit_transform(data_ar.group)\ndata_ar = data_ar.sample(frac = 1)\ndata_ar.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:13.238945Z","iopub.execute_input":"2022-02-20T18:41:13.239603Z","iopub.status.idle":"2022-02-20T18:41:13.260462Z","shell.execute_reply.started":"2022-02-20T18:41:13.239533Z","shell.execute_reply":"2022-02-20T18:41:13.259751Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"markdown","source":"## 6. Preprocessing/Cleaning on tweets","metadata":{}},{"cell_type":"markdown","source":"### 6.1 Help functions","metadata":{}},{"cell_type":"code","source":"def hash_fix(h):\n    h1 = re.sub(r'[0-9]+', '', h)\n    h2 = re.sub(r'#', '', h1)\n    h3 = segment(str(h2))\n    h4 = ' '.join(map(str, h3)) \n    return h4","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:16.953784Z","iopub.execute_input":"2022-02-20T18:41:16.954416Z","iopub.status.idle":"2022-02-20T18:41:16.960017Z","shell.execute_reply.started":"2022-02-20T18:41:16.954362Z","shell.execute_reply":"2022-02-20T18:41:16.959114Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"tok_ar = tk.WordTokenizer()\ntok_ar.train('/kaggle/input/twitter/ar_dataset.csv')\ndef prepro_ar(tweet):\n    arabic_diacritics = re.compile(\"\"\" ّ    | # Tashdid\n                             َ    | # Fatha\n                             ً    | # Tanwin Fath\n                             ُ    | # Damma\n                             ٌ    | # Tanwin Damm\n                             ِ    | # Kasra\n                             ٍ    | # Tanwin Kasr\n                             ْ    | # Sukun\n                             ـ     # Tatwil/Kashida\n                         \"\"\", re.VERBOSE)\n    \n    tweet = tweet.replace('user', '')\n    tweet = tweet.replace('@user', '')\n    tweet = re.sub( r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\",'',tweet)\n\n    tweet = tweet.replace('url', '')\n    tweet = re.sub(r\"\\p{P}\", lambda m: \"\", tweet)\n    tweet = re.sub(arabic_diacritics, '', str(tweet))\n    tweet = re.sub(r'(.)\\1+', \"\", tweet) \n    tweet = ar.strip_tashkeel(tweet)\n    tweet = ar.strip_tatweel(tweet)\n    tweet = tweet.replace(\"@\", \" \")\n    tweet = tweet.replace(\"_\", \" \")\n    tweet = re.sub(\"ى\", \"ي\", tweet)\n    tweet = re.sub(\"ؤ\", \"ء\", tweet)\n    tweet = re.sub(\"ئ\", \"ء\", tweet)\n    tweet = re.sub(\"ة\", \"ه\", tweet)\n    tweet = re.sub(\"گ\", \"ك\", tweet)\n    tweet = tweet.replace(\"آ\", \"ا\")\n    tweet = tweet.replace(\"إ\", \"ا\")\n    tweet = tweet.replace(\"أ\", \"ا\")\n    tweet = tweet.replace(\"ؤ\", \"و\")\n    tweet = tweet.replace(\"ئ\", \"ي\")\n    tweet = nltk.tokenize.word_tokenize(tweet)\n    tweet = [ISRIStemmer().suf32(w) for w in tweet]\n    for i in range(len(tweet)):\n        if tweet[i] == 'اه':\n            tweet[i] = 'الله'\n    return tweet","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:17.808931Z","iopub.execute_input":"2022-02-20T18:41:17.809260Z","iopub.status.idle":"2022-02-20T18:41:56.429930Z","shell.execute_reply.started":"2022-02-20T18:41:17.809227Z","shell.execute_reply":"2022-02-20T18:41:56.429165Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"contractions_fr = {\n        'administration':'admin',\n        'avec':'ac',\n        'beaucoup':'bp',\n        'c’est-à-dire':'cad',\n        'cependant':'cpd',\n        'chose':'ch',\n        'conclusion':'ccl',\n        'confer ':'cf',\n        'court terme':'ct',\n        'dans':'ds',\n        'dedans':'dd',\n        'définition':'déf',\n        'et cetera':'etc',\n        'être':'ê',\n        'exemple':'ex',\n        'extérieur':'ext',\n        'font':'ft',\n        'général':'gal',\n        'gouvernement':'gouv',\n        'grand':'gd',\n        'groupe':'gp',\n        'identique':'idel',\n        'introduction':'intro',\n        'jour':'jr',\n        'long terme':'lt',\n        'lorsque':'lsq',\n        'mais':'ms',\n        'même':'^m',\n        'moyen terme':'mt',\n        'nombre':'nb',\n        'nombreux':'nbx',\n        'nombre':'nb',\n        'nombreux':'nbx',\n        'observation':'obs',\n        'ordre du jour':'oj',\n        'page':'p',\n        'parce que':'pcq',\n        'pendant':'pdt',\n        'personne':'pers',\n        'point':'pt',\n        'peut-être':'pê',\n        'pour':'pr',\n        'pourtant':'prtt',\n        'quand':'qd',\n        'quantité':'qté',\n        'que':'q',\n        'quelqu’un':'qqn',\n        'quelque chose':'qqch',\n        'quelque':'qq',\n        'quelquefois':'qqf',\n        'question':'quest',\n        'rendez-vous':'rdv',\n        'responsabilité':'respité',\n        'seulement':'slt',\n        'solution':'sol',\n        'sont':'st',\n        'sous':'ss',\n        'souvent':'svt',\n        'temps':'tps',\n        'toujours':'tjrs',\n        'tous':'ts',\n        'tout':'tt',\n        'toute':'tte',\n        'toutes':'ttes',\n        'vous':'vs',\n        'le':'l\\'',\n        'me':'m\\'',\n        'de':'d\\'',\n        'te':'t\\'',\n        'se':'s\\'',\n        'ce':'c\\'',\n        'ne':'n\\'',\n        'que':'qu\\'',\n        'jusque':'jusqu\\'',\n        'lorsque':'lorsqu\\'',\n        'puisque':'puisqu\\'',\n        'quelque':'quelqu\\'',\n        'quoique':'quoiqu\\'',\n        'parce que':'parce qu\\'',\n        'tel que':'tel qu\\'',\n        'telle que':'telle qu\\'',       \n        'faculte':'fac',\n        'bien':'bin',    \n        'attend':'att',\n        'je': 'j\\'',\n        'rire':'ptdr',\n        'rire':'lol',\n        'rire':'lmfao',\n        'putin':'ptn',\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:56.431956Z","iopub.execute_input":"2022-02-20T18:41:56.432473Z","iopub.status.idle":"2022-02-20T18:41:56.446738Z","shell.execute_reply.started":"2022-02-20T18:41:56.432433Z","shell.execute_reply":"2022-02-20T18:41:56.445947Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"french_stopwords = nltk.corpus.stopwords.words('french')\nlemmatizer = FrenchLefffLemmatizer()\nspell = SpellChecker(language='fr')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:56.447883Z","iopub.execute_input":"2022-02-20T18:41:56.448258Z","iopub.status.idle":"2022-02-20T18:41:59.424504Z","shell.execute_reply.started":"2022-02-20T18:41:56.448229Z","shell.execute_reply":"2022-02-20T18:41:59.423608Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"def prepro_fr(tweet):\n    # prepare regex for char filtering\n    re_print = re.compile('[^%s]' % re.escape(string.printable))\n    # normalize unicode characters\n    tweet = normalize('NFD', tweet).encode('ascii','ignore')\n    tweet = tweet.decode('UTF-8')\n    #demojize\n    tweet = emoji.demojize(tweet)\n    if \"#\" in tweet:\n        tweet = hash_fix(tweet)\n    tweet = tweet.replace('user', '')\n    tweet = tweet.replace('@user', '')\n    tweet = tweet.replace('url', '')\n    tweet = re.sub( r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\",'',tweet)\n    # convert to lower case\n    tweet = tweet.lower()\n    tweet = tweet.replace('\\'', '\\' ') \n    # remove punctuation\n    tweet = re.sub(r\"\\p{P}\", lambda m: \"-\" if m.group(0) == \"-\" else \"\", tweet)\n    # tokenization\n    tweet = nltk.tokenize.word_tokenize(tweet)\n    #contractions\n    tweet = [list(contractions_fr.keys())[list(contractions_fr.values()).index(word)] if word in contractions_fr.values() else word for word in tweet]\n    \n    # stop words\n    tweet = [w for w in tweet if w not in french_stopwords]\n    sc = 'j[a-z]*'\n    v = '[^aeyouisch]*'\n    for w in tweet:\n        x = re.findall(sc,w)\n        xx = re.findall(v,w)\n        if len(x)!=0:\n            w = x[0].replace('j', 'je ')\n            if len(x)>=3:\n                w = w.replace(xx[0], '')\n    # remove non-printable chars form each token\n    tweet = [re_print.sub('', w) for w in tweet]\n    # lemmatization\n    tweet = [lemmatizer.lemmatize(w) for w in tweet]\n    return tweet","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:59.426863Z","iopub.execute_input":"2022-02-20T18:41:59.427116Z","iopub.status.idle":"2022-02-20T18:41:59.442316Z","shell.execute_reply.started":"2022-02-20T18:41:59.427086Z","shell.execute_reply":"2022-02-20T18:41:59.441400Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"markdown","source":"### 6.2 Arabic","metadata":{}},{"cell_type":"code","source":"data_ar.tweet = data_ar.tweet.apply(lambda t: prepro_ar(t))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:41:59.443669Z","iopub.execute_input":"2022-02-20T18:41:59.443967Z","iopub.status.idle":"2022-02-20T18:42:00.393254Z","shell.execute_reply.started":"2022-02-20T18:41:59.443934Z","shell.execute_reply":"2022-02-20T18:42:00.392370Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"data_ar.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:42:00.394702Z","iopub.execute_input":"2022-02-20T18:42:00.395005Z","iopub.status.idle":"2022-02-20T18:42:00.410098Z","shell.execute_reply.started":"2022-02-20T18:42:00.394965Z","shell.execute_reply":"2022-02-20T18:42:00.409149Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"markdown","source":"### 6.3 French","metadata":{}},{"cell_type":"code","source":"data_fr.tweet = data_fr.tweet.apply(lambda t: prepro_fr(t))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:42:00.411771Z","iopub.execute_input":"2022-02-20T18:42:00.412548Z","iopub.status.idle":"2022-02-20T18:42:35.404877Z","shell.execute_reply.started":"2022-02-20T18:42:00.412499Z","shell.execute_reply":"2022-02-20T18:42:35.403879Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"code","source":"data_fr.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:42:35.406243Z","iopub.execute_input":"2022-02-20T18:42:35.406517Z","iopub.status.idle":"2022-02-20T18:42:35.420806Z","shell.execute_reply.started":"2022-02-20T18:42:35.406486Z","shell.execute_reply":"2022-02-20T18:42:35.419800Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"markdown","source":"## 7. Splitting Data","metadata":{}},{"cell_type":"markdown","source":"## 7.1 Arabic","metadata":{}},{"cell_type":"code","source":"labels_ar = data_ar.target.values\ndata_ar = data_ar.drop(columns={'target'})","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:42:35.422308Z","iopub.execute_input":"2022-02-20T18:42:35.422591Z","iopub.status.idle":"2022-02-20T18:42:35.433282Z","shell.execute_reply.started":"2022-02-20T18:42:35.422561Z","shell.execute_reply":"2022-02-20T18:42:35.432426Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"X_train_ar,X_test_ar, y_train_ar,y_test_ar = train_test_split(data_ar,\n                                                              labels_ar,\n                                                              test_size=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:42:35.435247Z","iopub.execute_input":"2022-02-20T18:42:35.435506Z","iopub.status.idle":"2022-02-20T18:42:35.447841Z","shell.execute_reply.started":"2022-02-20T18:42:35.435476Z","shell.execute_reply":"2022-02-20T18:42:35.446842Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"markdown","source":"### 7.2 French","metadata":{}},{"cell_type":"code","source":"labels_fr = data_fr.target.values\ndata_fr = data_fr.drop(columns={'target'})","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:42:48.499034Z","iopub.execute_input":"2022-02-20T18:42:48.499873Z","iopub.status.idle":"2022-02-20T18:42:48.505883Z","shell.execute_reply.started":"2022-02-20T18:42:48.499837Z","shell.execute_reply":"2022-02-20T18:42:48.504943Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"X_train_fr,X_test_fr, y_train_fr,y_test_fr = train_test_split(data_fr,\n                                                              labels_fr,\n                                                              test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:42:49.363456Z","iopub.execute_input":"2022-02-20T18:42:49.363739Z","iopub.status.idle":"2022-02-20T18:42:49.372005Z","shell.execute_reply.started":"2022-02-20T18:42:49.363710Z","shell.execute_reply":"2022-02-20T18:42:49.371123Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"markdown","source":"## 8. Word Embedding","metadata":{}},{"cell_type":"code","source":"embed_dim = 300 ","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:42:52.330992Z","iopub.execute_input":"2022-02-20T18:42:52.331316Z","iopub.status.idle":"2022-02-20T18:42:52.335724Z","shell.execute_reply.started":"2022-02-20T18:42:52.331279Z","shell.execute_reply":"2022-02-20T18:42:52.334708Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"markdown","source":"### 8.1 Arabic","metadata":{}},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.vec.gz","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:55:18.511480Z","iopub.execute_input":"2022-02-20T17:55:18.512087Z","iopub.status.idle":"2022-02-20T17:56:19.271241Z","shell.execute_reply.started":"2022-02-20T17:55:18.512028Z","shell.execute_reply":"2022-02-20T17:56:19.270295Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"!gunzip cc.ar.300.vec.gz","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:56:19.274019Z","iopub.execute_input":"2022-02-20T17:56:19.275027Z","iopub.status.idle":"2022-02-20T17:57:02.525353Z","shell.execute_reply.started":"2022-02-20T17:56:19.274966Z","shell.execute_reply":"2022-02-20T17:57:02.524304Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"f_ar = open('cc.ar.300.vec', encoding='utf-8')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:43:02.152277Z","iopub.execute_input":"2022-02-20T18:43:02.152629Z","iopub.status.idle":"2022-02-20T18:43:02.157061Z","shell.execute_reply.started":"2022-02-20T18:43:02.152592Z","shell.execute_reply":"2022-02-20T18:43:02.156449Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"code","source":"#loading pretrained model to word vecs\nembeddings_index_ar = {}\nfor line in tqdm(f_ar):\n    values = line.split()\n    word = values[0]\n    vector = np.asarray(values[1:],'float32')\n    embeddings_index_ar[word]=vector\nf_ar.close()\n\nprint('found %s word vectors' % len(embeddings_index_ar))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:43:03.664046Z","iopub.execute_input":"2022-02-20T18:43:03.665018Z","iopub.status.idle":"2022-02-20T18:46:20.945908Z","shell.execute_reply.started":"2022-02-20T18:43:03.664960Z","shell.execute_reply":"2022-02-20T18:46:20.944990Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"X_train_ar1 = list(X_train_ar.tweet.values)\nX_test_ar1 = list(X_test_ar.tweet.values)\n\ntok_ar = Tokenizer()\ntok_ar.fit_on_texts(data_ar.tweet.values)\nword_index_ar = tok_ar.word_index\n\n#text to integer sequence\nX_train_ar1 = tok_ar.texts_to_sequences(X_train_ar1)\nX_test_ar1 = tok_ar.texts_to_sequences(X_test_ar1)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:48:42.841829Z","iopub.execute_input":"2022-02-20T18:48:42.842206Z","iopub.status.idle":"2022-02-20T18:48:43.035010Z","shell.execute_reply.started":"2022-02-20T18:48:42.842168Z","shell.execute_reply":"2022-02-20T18:48:43.034270Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"code","source":"tweets_length_ar= [len(X_train_ar1[i]) for i in range(len(X_train_ar1))]\nmax_seq_len_ar = max(tweets_length_ar)\nprint(max_seq_len_ar)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:49:49.639241Z","iopub.execute_input":"2022-02-20T18:49:49.639905Z","iopub.status.idle":"2022-02-20T18:49:49.646631Z","shell.execute_reply.started":"2022-02-20T18:49:49.639853Z","shell.execute_reply":"2022-02-20T18:49:49.645850Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"#padding\nX_train_ar1 = pad_sequences(X_train_ar1, padding='post', maxlen=max_seq_len_ar)\nX_test_ar1 = pad_sequences(X_test_ar1, padding='post', maxlen=max_seq_len_ar)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:49:56.093233Z","iopub.execute_input":"2022-02-20T18:49:56.093602Z","iopub.status.idle":"2022-02-20T18:49:56.114994Z","shell.execute_reply.started":"2022-02-20T18:49:56.093560Z","shell.execute_reply":"2022-02-20T18:49:56.113891Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"X_train_ar2 = X_train_ar[['sentiment', 'directness', 'annotator_sentiment', 'group']].values\nX_test_ar2 = X_test_ar[['sentiment', 'directness', 'annotator_sentiment', 'group']].values","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:49:57.354182Z","iopub.execute_input":"2022-02-20T18:49:57.354911Z","iopub.status.idle":"2022-02-20T18:49:57.360686Z","shell.execute_reply.started":"2022-02-20T18:49:57.354867Z","shell.execute_reply":"2022-02-20T18:49:57.360070Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"code","source":"#embedding matrix\nprint('preparing embedding matrix...')\nwords_not_found_ar = []\nnb_words_ar = len(word_index_ar)+1\nembedding_matrix_ar = np.zeros((nb_words_ar, embed_dim))\nfor word, i in word_index_ar.items():\n    embedding_vector = embeddings_index_ar.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix_ar[i] = embedding_vector\n    else:\n        words_not_found_ar.append(word)\nprint('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix_ar, axis=1) == 0))\nprint(len(embedding_matrix_ar))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:51:18.624231Z","iopub.execute_input":"2022-02-20T18:51:18.624964Z","iopub.status.idle":"2022-02-20T18:51:18.658053Z","shell.execute_reply.started":"2022-02-20T18:51:18.624922Z","shell.execute_reply":"2022-02-20T18:51:18.657033Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"markdown","source":"### 8.2 French","metadata":{}},{"cell_type":"code","source":"#Loading embedding  model!\n!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.vec.gz","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:00:15.739644Z","iopub.execute_input":"2022-02-20T18:00:15.739945Z","iopub.status.idle":"2022-02-20T18:01:12.150493Z","shell.execute_reply.started":"2022-02-20T18:00:15.739913Z","shell.execute_reply":"2022-02-20T18:01:12.149441Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"!gunzip cc.fr.300.vec.gz","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:01:12.152172Z","iopub.execute_input":"2022-02-20T18:01:12.152481Z","iopub.status.idle":"2022-02-20T18:01:53.731943Z","shell.execute_reply.started":"2022-02-20T18:01:12.152437Z","shell.execute_reply":"2022-02-20T18:01:53.730960Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"f_fr = open('cc.fr.300.vec', encoding='utf-8')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:01:53.733375Z","iopub.execute_input":"2022-02-20T18:01:53.733651Z","iopub.status.idle":"2022-02-20T18:01:53.742016Z","shell.execute_reply.started":"2022-02-20T18:01:53.733618Z","shell.execute_reply":"2022-02-20T18:01:53.741402Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"#loading pretrained model to word vecs\nembeddings_index_fr = {}\nfor line in tqdm(f_fr):\n    values = line.split()\n    word = values[0]\n    vector = np.asarray(values[1:],'float32')\n    embeddings_index_fr[word]=vector\nf_fr.close()\n\nprint('found %s word vectors' % len(embeddings_index_fr))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:01:53.743620Z","iopub.execute_input":"2022-02-20T18:01:53.744088Z","iopub.status.idle":"2022-02-20T18:04:56.757846Z","shell.execute_reply.started":"2022-02-20T18:01:53.744052Z","shell.execute_reply":"2022-02-20T18:04:56.756261Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"X_train_fr1 = list(X_train_fr.tweet.values)\nX_test_fr1 = list(X_test_fr.tweet.values)\n\ntok_fr = Tokenizer()\ntok_fr.fit_on_texts(data_fr.tweet.values)\n#text to integer sequence\nX_train_fr1 = tok_fr.texts_to_sequences(X_train_fr1)\nX_test_fr1 = tok_fr.texts_to_sequences(X_test_fr1)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:04:56.760954Z","iopub.execute_input":"2022-02-20T18:04:56.761295Z","iopub.status.idle":"2022-02-20T18:04:56.992029Z","shell.execute_reply.started":"2022-02-20T18:04:56.761263Z","shell.execute_reply":"2022-02-20T18:04:56.990897Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"#counting the length of the tweet and taking the max\ntweets_length_fr= [len(X_train_fr1[i]) for i in range(len(X_train_fr1))]\nmax_seq_len_fr = max(tweets_length_fr)\nprint(max_seq_len_fr)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:04:56.993439Z","iopub.execute_input":"2022-02-20T18:04:56.993696Z","iopub.status.idle":"2022-02-20T18:04:57.001635Z","shell.execute_reply.started":"2022-02-20T18:04:56.993664Z","shell.execute_reply":"2022-02-20T18:04:57.000681Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"#padding\nX_train_fr1 = pad_sequences(X_train_fr1, maxlen=max_seq_len_fr)\nX_test_fr1 = pad_sequences(X_test_fr1, maxlen=max_seq_len_fr)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:04:57.003191Z","iopub.execute_input":"2022-02-20T18:04:57.003512Z","iopub.status.idle":"2022-02-20T18:04:57.079809Z","shell.execute_reply.started":"2022-02-20T18:04:57.003475Z","shell.execute_reply":"2022-02-20T18:04:57.078822Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"X_train_fr2 = X_train_fr[['sentiment', 'directness', 'annotator_sentiment', 'group']].values\nX_test_fr2 = X_test_fr[['sentiment', 'directness', 'annotator_sentiment', 'group']].values","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:04:57.081466Z","iopub.execute_input":"2022-02-20T18:04:57.081891Z","iopub.status.idle":"2022-02-20T18:04:57.089216Z","shell.execute_reply.started":"2022-02-20T18:04:57.081854Z","shell.execute_reply":"2022-02-20T18:04:57.088211Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"#embedding matrix\nprint('preparing embedding matrix...')\nwords_not_found_fr = []\nword_index_fr = tok_fr.word_index\nnb_words_fr = len(word_index_fr)+1\nembedding_matrix_fr = np.zeros((nb_words_fr, embed_dim))\nfor word, i in word_index_fr.items():\n    embedding_vector = embeddings_index_fr.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix_fr[i] = embedding_vector\n    else:\n        words_not_found_fr.append(word)\nprint('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix_fr, axis=1) == 0))\nprint(len(embedding_matrix_fr))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:04:57.090653Z","iopub.execute_input":"2022-02-20T18:04:57.091142Z","iopub.status.idle":"2022-02-20T18:04:57.183163Z","shell.execute_reply.started":"2022-02-20T18:04:57.091100Z","shell.execute_reply":"2022-02-20T18:04:57.182237Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"## 9. Classification Model","metadata":{}},{"cell_type":"markdown","source":"### 9.1 Building model","metadata":{}},{"cell_type":"code","source":"input_fr_1 = Input(shape=(max_seq_len_fr,))\ninput_ar_1 = Input(shape=(max_seq_len_ar,))\ninput_2 = Input(shape=(4,))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:53:03.906306Z","iopub.execute_input":"2022-02-20T18:53:03.906676Z","iopub.status.idle":"2022-02-20T18:53:03.916481Z","shell.execute_reply.started":"2022-02-20T18:53:03.906633Z","shell.execute_reply":"2022-02-20T18:53:03.915567Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"code","source":"embedding_layer_fr = Embedding(\n                            nb_words_fr, \n                            embed_dim,  \n                            weights=[embedding_matrix_fr],\n                            trainable=False,\n                            input_length=max_seq_len_fr,\n                    )(input_fr_1)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:53:07.307979Z","iopub.execute_input":"2022-02-20T18:53:07.308313Z","iopub.status.idle":"2022-02-20T18:53:07.422065Z","shell.execute_reply.started":"2022-02-20T18:53:07.308278Z","shell.execute_reply":"2022-02-20T18:53:07.421078Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"embedding_layer_ar = Embedding(\n                            nb_words_ar, \n                            embed_dim,  \n                            weights=[embedding_matrix_ar],\n                            trainable=False,\n                            input_length=max_seq_len_ar,\n                    )(input_ar_1)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:53:09.228314Z","iopub.execute_input":"2022-02-20T18:53:09.228703Z","iopub.status.idle":"2022-02-20T18:53:09.255771Z","shell.execute_reply.started":"2022-02-20T18:53:09.228668Z","shell.execute_reply":"2022-02-20T18:53:09.254899Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"def NN(lang,input_1,input_2):\n    if lang=='AR':  \n        embedding_layer = embedding_layer_ar\n    else:\n        embedding_layer = embedding_layer_fr\n\n    lstm = LSTM(64)(embedding_layer)\n    dense_layer_1 = Dense(10, activation='relu')(input_2)\n    dense_layer_2 = Dense(10, activation='relu')(dense_layer_1)\n    concat_layer = Concatenate()([lstm, dense_layer_2])\n    dense_layer_3 = Dense(10, activation='relu')(concat_layer)\n    \n    output = Dense(1, activation='sigmoid')(dense_layer_3)\n    \n    model = Model(inputs=[input_1, input_2], outputs=output)\n    \n    plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:53:11.127233Z","iopub.execute_input":"2022-02-20T18:53:11.127559Z","iopub.status.idle":"2022-02-20T18:53:11.135277Z","shell.execute_reply.started":"2022-02-20T18:53:11.127523Z","shell.execute_reply":"2022-02-20T18:53:11.134307Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"markdown","source":"### 9.2 Training Model","metadata":{}},{"cell_type":"code","source":"#hyperparameters\nnum_epochs = 10\nbatch_size = 32\nearly = callbacks.EarlyStopping(monitor='val_loss',\n                                min_delta=0, \n                                patience=3,\n                                verbose=1, \n                                mode='auto')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:53:13.451719Z","iopub.execute_input":"2022-02-20T18:53:13.452322Z","iopub.status.idle":"2022-02-20T18:53:13.458020Z","shell.execute_reply.started":"2022-02-20T18:53:13.452270Z","shell.execute_reply":"2022-02-20T18:53:13.457178Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"markdown","source":"### 9.2.1 French","metadata":{}},{"cell_type":"code","source":"model_fr = NN('FR',input_fr_1,input_2)\nmodel_fr.compile(optimizer = 'adam',\n                 loss = 'binary_crossentropy', \n                 metrics = ['accuracy'])\n\nprint('French:')\nXfr = [X_train_fr1,X_train_fr2]\nhistory_fr = model_fr.fit(Xfr,\n                          y_train_fr.astype(np.float32),\n                          batch_size=batch_size,\n                          epochs=num_epochs,\n                          validation_split=0.2,\n                          callbacks = [early],\n                          verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:04:57.563299Z","iopub.execute_input":"2022-02-20T18:04:57.564158Z","iopub.status.idle":"2022-02-20T18:07:06.807740Z","shell.execute_reply.started":"2022-02-20T18:04:57.564114Z","shell.execute_reply":"2022-02-20T18:07:06.806522Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"### 9.2.2 Arabic","metadata":{}},{"cell_type":"code","source":"model_ar = NN('AR',input_ar_1,input_2)\nmodel_ar.compile(optimizer = 'adam',\n                 loss = 'binary_crossentropy', \n                 metrics = ['accuracy'])\n\nprint('Arabic:')\nXar = [np.asarray(X_train_ar1), np.asarray(X_train_ar2)]\nhistory_ar = model_ar.fit(Xar,\n                          y_train_ar.astype(np.float32),\n                          batch_size=batch_size,\n                          epochs=num_epochs,\n                          validation_split=0.2,\n                          callbacks = [early],\n                          verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:53:20.415485Z","iopub.execute_input":"2022-02-20T18:53:20.415876Z","iopub.status.idle":"2022-02-20T18:53:46.784716Z","shell.execute_reply.started":"2022-02-20T18:53:20.415834Z","shell.execute_reply":"2022-02-20T18:53:46.783855Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"markdown","source":"### 9.3 Evaluating & Testing model","metadata":{}},{"cell_type":"markdown","source":"#### 9.3.1 Help functions","metadata":{}},{"cell_type":"code","source":"def plot_acc_loss(history):\n    \"\"\"\n    Plot accuracy and loss of a model\n    @params:\n            - history: history of the model\n    @return:\n            plots\n    \"\"\"\n    fig,ax = plt.subplots(1,2,figsize=(10,5))\n    l = list(history.history.keys())\n    print(l)\n    # accuracy plot\n    ax[0].plot(history.history[l[1]])\n    ax[0].plot(history.history[l[3]])\n    ax[0].set_title('model accuracy')\n    ax[0].set_ylabel('accuracy')\n    ax[0].set_xlabel('epoch')\n    ax[0].legend(['train', 'test'], loc='upper left')\n    # loss plot\n    ax[1].plot(history.history[l[0]])\n    ax[1].plot(history.history[l[2]])\n    ax[1].set_title('model loss')\n    ax[1].set_ylabel('loss')\n    ax[1].set_xlabel('epoch')\n    ax[1].legend(['train', 'test'], loc='upper left')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:54:04.824938Z","iopub.execute_input":"2022-02-20T18:54:04.825242Z","iopub.status.idle":"2022-02-20T18:54:04.836200Z","shell.execute_reply.started":"2022-02-20T18:54:04.825208Z","shell.execute_reply":"2022-02-20T18:54:04.835228Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"def predicted_label(model,x):\n    pred = model.predict(x)\n    lab_pred = []\n    for i in range(len(pred)):\n        if pred[i][0]>=0.5:\n            lab_pred.append(1)\n        else:\n            lab_pred.append(0)\n    return lab_pred","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:54:06.258627Z","iopub.execute_input":"2022-02-20T18:54:06.258915Z","iopub.status.idle":"2022-02-20T18:54:06.264624Z","shell.execute_reply.started":"2022-02-20T18:54:06.258885Z","shell.execute_reply":"2022-02-20T18:54:06.263646Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"code","source":"def plot_cm(model,x,y):\n    pred = model.predict(x)\n    y_pred = predicted_label(model,x)\n    cm = confusion_matrix(list(y),y_pred)  \n    sn.heatmap(cm, annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:54:07.088164Z","iopub.execute_input":"2022-02-20T18:54:07.088473Z","iopub.status.idle":"2022-02-20T18:54:07.093835Z","shell.execute_reply.started":"2022-02-20T18:54:07.088439Z","shell.execute_reply":"2022-02-20T18:54:07.092827Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"markdown","source":"#### 9.3.2 Arabic","metadata":{}},{"cell_type":"code","source":"plot_acc_loss(history_ar)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:54:09.112764Z","iopub.execute_input":"2022-02-20T18:54:09.113297Z","iopub.status.idle":"2022-02-20T18:54:09.502945Z","shell.execute_reply.started":"2022-02-20T18:54:09.113248Z","shell.execute_reply":"2022-02-20T18:54:09.499951Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"code","source":"print(\"Confusion Matrix for arabic dataset\")\nXtestar = [np.asarray(X_test_ar1), np.asarray(X_test_ar2)]\nplot_cm(model_ar,Xtestar,y_test_ar)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:54:15.896380Z","iopub.execute_input":"2022-02-20T18:54:15.896684Z","iopub.status.idle":"2022-02-20T18:54:17.035002Z","shell.execute_reply.started":"2022-02-20T18:54:15.896649Z","shell.execute_reply":"2022-02-20T18:54:17.034281Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"code","source":"test_loss_ar, test_acc_ar = model_ar.evaluate(Xtestar,y_test_ar.astype(np.float32))\nprint('Test accuracy:', test_acc_ar)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:54:17.966155Z","iopub.execute_input":"2022-02-20T18:54:17.966625Z","iopub.status.idle":"2022-02-20T18:54:18.153005Z","shell.execute_reply.started":"2022-02-20T18:54:17.966583Z","shell.execute_reply":"2022-02-20T18:54:18.151914Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"pred_ar =predicted_label(model_ar,Xtestar)\n# accuracy: (tp + tn) / (p + n)\naccuracy_ar = accuracy_score(list(y_test_ar), pred_ar)\nprint('Accuracy: %f' % accuracy_ar)\n# precision tp / (tp + fp)\nprecision_ar = precision_score(list(y_test_ar), pred_ar)\nprint('Precision: %f' % precision_ar)\n# recall: tp / (tp + fn)\nrecall_ar = recall_score(list(y_test_ar), pred_ar)\nprint('Recall: %f' % recall_ar)\n# f1: 2 tp / (2 tp + fp + fn)\nf1_ar = f1_score(list(y_test_ar), pred_ar)\nprint('F1 score: %f' % f1_ar)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:54:21.208041Z","iopub.execute_input":"2022-02-20T18:54:21.208385Z","iopub.status.idle":"2022-02-20T18:54:21.376674Z","shell.execute_reply.started":"2022-02-20T18:54:21.208344Z","shell.execute_reply":"2022-02-20T18:54:21.375761Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"markdown","source":"#### 9.3.4 French","metadata":{}},{"cell_type":"code","source":"plot_acc_loss(history_fr)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:07:32.876302Z","iopub.status.idle":"2022-02-20T18:07:32.877200Z","shell.execute_reply.started":"2022-02-20T18:07:32.876843Z","shell.execute_reply":"2022-02-20T18:07:32.876881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Confusion Matrix for french dataset\")\nXtestfr = [np.asarray(X_test_fr1), np.asarray(X_test_fr2)]\nplot_cm(model_fr,Xtestfr,y_test_fr)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:07:32.878715Z","iopub.status.idle":"2022-02-20T18:07:32.879778Z","shell.execute_reply.started":"2022-02-20T18:07:32.879546Z","shell.execute_reply":"2022-02-20T18:07:32.879591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = model_fr.evaluate(Xtestfr,y_test_fr.astype(np.float32))\nprint('Test accuracy:', test_acc)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:07:32.880779Z","iopub.status.idle":"2022-02-20T18:07:32.881124Z","shell.execute_reply.started":"2022-02-20T18:07:32.880936Z","shell.execute_reply":"2022-02-20T18:07:32.880963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_fr =predicted_label(model_fr,Xtestfr)\n# accuracy: (tp + tn) / (p + n)\naccuracy_fr = accuracy_score(list(y_test_fr), pred_fr)\nprint('Accuracy: %f' % accuracy_fr)\n# precision tp / (tp + fp)\nprecision_fr = precision_score(list(y_test_fr), pred_fr)\nprint('Precision: %f' % precision_fr)\n# recall: tp / (tp + fn)\nrecall_fr = recall_score(list(y_test_fr), pred_fr)\n\nprint('Recall: %f' % recall_fr)\n# f1: 2 tp / (2 tp + fp + fn)\nf1_fr = f1_score(list(y_test_fr), pred_fr)\nprint('F1 score: %f' % f1_fr)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:07:32.885541Z","iopub.status.idle":"2022-02-20T18:07:32.885912Z","shell.execute_reply.started":"2022-02-20T18:07:32.885734Z","shell.execute_reply":"2022-02-20T18:07:32.885755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}